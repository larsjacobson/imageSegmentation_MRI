import numpy as np import tensorflow as tf from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate from tensorflow.keras.models import Model from tensorflow.keras.optimizers import Adam from tensorflow.keras.callbacks import ProgbarLogger from sklearn.model_selection import train_test_split  # Corrected import from skimage.transform import resize from skimage.io import imread import os  # Data Loading and Preprocessing Functions def load_png_image(path):     print(f"Loading image: {path}")     """Load a PNG image."""     image = imread(path)     image = image.astype(np.float32)     image /= np.max(image)  # Normalize to [0, 1]     return image  def load_mask_image(path):     print(f"Loading mask: {path}")     """Load a mask image (assumed to be in PNG format)."""     mask = imread(path, as_gray=True)     return mask def load_data(image_dir, mask_dir):     print("Loading data...")     images = []     masks = []      for filename in os.listdir(image_dir):         if filename.endswith('_image.png'):             img_path = os.path.join(image_dir, filename)             mask_path = os.path.join(mask_dir, filename.replace('_image.png', '_mask.png'))              img = load_png_image(img_path)             mask = load_mask_image(mask_path)              # Resize the image and mask to ensure consistency             img_resized = resize(img, (128, 128, 1), anti_aliasing=True)             mask_resized = resize(mask, (128, 128, 1), anti_aliasing=True)              images.append(img_resized)             masks.append(mask_resized)      return np.array(images), np.array(masks)  # U-Net Model Function def unet(input_size=(128, 128, 1)):     print("Building U-Net model...")     inputs = Input(input_size)     # Down-sampling     conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)     conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)      # More layers can be added here for a deeper network      # Up-sampling     up1 = UpSampling2D(size=(2, 2))(pool1)     conv2 = Conv2D(64, 2, activation='relu', padding='same')(up1)     merge1 = concatenate([conv1, conv2], axis=3)     conv2 = Conv2D(64, 3, activation='relu', padding='same')(merge1)     conv2 = Conv2D(64, 3, activation='relu', padding='same')(conv2)      conv3 = Conv2D(2, 3, activation='relu', padding='same')(conv2)     conv4 = Conv2D(1, 1, activation='sigmoid')(conv3)      model = Model(inputs=inputs, outputs=conv4)     return model  # Create a ProgbarLogger callback progbar_logger = ProgbarLogger(count_mode='steps', stateful_metrics=None)  # Main Execution if __name__ == "__main__":     print("Script started.")     # Load data     image_dir = 'train/image'     mask_dir = 'train/mask'     images, masks = load_data(image_dir, mask_dir)      # Resize and split data     print("Resizing and splitting data...")     image_size = 128     images_resized = np.array([resize(image, (image_size, image_size, 1)) for image in images])     masks_resized = np.array([resize(mask, (image_size, image_size, 1)) for mask in masks])     X_train, X_val, y_train, y_val = train_test_split(images_resized, masks_resized, test_size=0.1, random_state=42)     print("Data ready for training.")      # Build and compile the model     model = unet()     model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])     print("Model compiled.")      # Train the model with ProgbarLogger callback     print("Starting training...")     history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_val, y_val), callbacks=[progbar_logger])     print("Training complete.")      # Save the model     model.save('prostate_segmentation_model.h5')     print("Model saved. Script finished.")
